{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9ea9f79",
   "metadata": {},
   "source": [
    "# Looking at the FSRL steering vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fsrl.utils import SAEfeatureAnalyzer\n",
    "from fsrl import SAEAdapter, HookedModel\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da4bd882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthijs/programming/feature-steering-RL/.venv/lib/python3.10/site-packages/sae_lens/sae.py:151: UserWarning: \n",
      "This SAE has non-empty model_from_pretrained_kwargs. \n",
      "For optimal performance, load the model like so:\n",
      "model = HookedSAETransformer.from_pretrained_no_processing(..., **cfg.model_from_pretrained_kwargs)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "release = \"gpt2-small-res-jb\"\n",
    "sae_id = \"blocks.7.hook_resid_pre\"\n",
    "\n",
    "adapter_kwargs = {\n",
    "    \"use_lora_adapter\": True,\n",
    "    \"lora_rank\": 64,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"fusion_mode\": \"additive\",\n",
    "}\n",
    "\n",
    "sae, cfg_dict, sparsity = SAEAdapter.from_pretrained(release, sae_id, device=device, **adapter_kwargs)\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)\n",
    "sae_model = HookedModel(model, sae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe607dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching all explanations for gpt2-small/7-res-jb...\n",
      "Successfully loaded 24570 feature explanations.\n"
     ]
    }
   ],
   "source": [
    "sae_analyzer = SAEfeatureAnalyzer(sae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4f95ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_idx</th>\n",
       "      <th>steering_value</th>\n",
       "      <th>description</th>\n",
       "      <th>modelId</th>\n",
       "      <th>layer</th>\n",
       "      <th>index</th>\n",
       "      <th>explanationModelName</th>\n",
       "      <th>typeName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15895</td>\n",
       "      <td>-3.847262</td>\n",
       "      <td>terms related to various disciplines and areas...</td>\n",
       "      <td>gpt2-small</td>\n",
       "      <td>7-res-jb</td>\n",
       "      <td>15895</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>oai_token-act-pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23399</td>\n",
       "      <td>-3.844694</td>\n",
       "      <td>words related to pulses</td>\n",
       "      <td>gpt2-small</td>\n",
       "      <td>7-res-jb</td>\n",
       "      <td>23399</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>oai_token-act-pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5530</td>\n",
       "      <td>-3.705429</td>\n",
       "      <td>links and references to related content or art...</td>\n",
       "      <td>gpt2-small</td>\n",
       "      <td>7-res-jb</td>\n",
       "      <td>5530</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>oai_token-act-pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6324</td>\n",
       "      <td>3.686178</td>\n",
       "      <td>code snippets containing error handling logic</td>\n",
       "      <td>gpt2-small</td>\n",
       "      <td>7-res-jb</td>\n",
       "      <td>6324</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>oai_token-act-pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22374</td>\n",
       "      <td>-3.627533</td>\n",
       "      <td>words related to locations or companies with t...</td>\n",
       "      <td>gpt2-small</td>\n",
       "      <td>7-res-jb</td>\n",
       "      <td>22374</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>oai_token-act-pair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_idx  steering_value  \\\n",
       "0        15895       -3.847262   \n",
       "1        23399       -3.844694   \n",
       "2         5530       -3.705429   \n",
       "3         6324        3.686178   \n",
       "4        22374       -3.627533   \n",
       "\n",
       "                                         description     modelId     layer  \\\n",
       "0  terms related to various disciplines and areas...  gpt2-small  7-res-jb   \n",
       "1                            words related to pulses  gpt2-small  7-res-jb   \n",
       "2  links and references to related content or art...  gpt2-small  7-res-jb   \n",
       "3      code snippets containing error handling logic  gpt2-small  7-res-jb   \n",
       "4  words related to locations or companies with t...  gpt2-small  7-res-jb   \n",
       "\n",
       "   index explanationModelName            typeName  \n",
       "0  15895        gpt-3.5-turbo  oai_token-act-pair  \n",
       "1  23399        gpt-3.5-turbo  oai_token-act-pair  \n",
       "2   5530        gpt-3.5-turbo  oai_token-act-pair  \n",
       "3   6324        gpt-3.5-turbo  oai_token-act-pair  \n",
       "4  22374        gpt-3.5-turbo  oai_token-act-pair  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assume analyzer is your SAEfeatureAnalyzer instance\n",
    "steering_vec = torch.randn(sae_analyzer.sae.cfg.d_sae)  # example steering vector\n",
    "df = sae_analyzer.get_steered_features_info(steering_vec, threshold=0.01)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4c23290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_idx</th>\n",
       "      <th>steering_value</th>\n",
       "      <th>description</th>\n",
       "      <th>modelId</th>\n",
       "      <th>layer</th>\n",
       "      <th>index</th>\n",
       "      <th>explanationModelName</th>\n",
       "      <th>typeName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10753</td>\n",
       "      <td>4.481459</td>\n",
       "      <td>words related to the city of St. Louis</td>\n",
       "      <td>gpt2-small</td>\n",
       "      <td>7-res-jb</td>\n",
       "      <td>10753</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>oai_token-act-pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24437</td>\n",
       "      <td>-3.991761</td>\n",
       "      <td>phrases or sentences ending with a question mark</td>\n",
       "      <td>gpt2-small</td>\n",
       "      <td>7-res-jb</td>\n",
       "      <td>24437</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>oai_token-act-pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21031</td>\n",
       "      <td>3.906598</td>\n",
       "      <td>words related to simplicity or basic concepts</td>\n",
       "      <td>gpt2-small</td>\n",
       "      <td>7-res-jb</td>\n",
       "      <td>21031</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>oai_token-act-pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14150</td>\n",
       "      <td>3.844881</td>\n",
       "      <td>proper nouns related to the name \"Mankato.\"</td>\n",
       "      <td>gpt2-small</td>\n",
       "      <td>7-res-jb</td>\n",
       "      <td>14150</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>oai_token-act-pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18389</td>\n",
       "      <td>-3.825272</td>\n",
       "      <td>phrases related to comparing different entitie...</td>\n",
       "      <td>gpt2-small</td>\n",
       "      <td>7-res-jb</td>\n",
       "      <td>18389</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>oai_token-act-pair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_idx  steering_value  \\\n",
       "0        10753        4.481459   \n",
       "1        24437       -3.991761   \n",
       "2        21031        3.906598   \n",
       "3        14150        3.844881   \n",
       "4        18389       -3.825272   \n",
       "\n",
       "                                         description     modelId     layer  \\\n",
       "0             words related to the city of St. Louis  gpt2-small  7-res-jb   \n",
       "1   phrases or sentences ending with a question mark  gpt2-small  7-res-jb   \n",
       "2      words related to simplicity or basic concepts  gpt2-small  7-res-jb   \n",
       "3        proper nouns related to the name \"Mankato.\"  gpt2-small  7-res-jb   \n",
       "4  phrases related to comparing different entitie...  gpt2-small  7-res-jb   \n",
       "\n",
       "   index explanationModelName            typeName  \n",
       "0  10753        gpt-3.5-turbo  oai_token-act-pair  \n",
       "1  24437        gpt-3.5-turbo  oai_token-act-pair  \n",
       "2  21031        gpt-3.5-turbo  oai_token-act-pair  \n",
       "3  14150        gpt-3.5-turbo  oai_token-act-pair  \n",
       "4  18389        gpt-3.5-turbo  oai_token-act-pair  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_top_5 = sae_analyzer.get_steered_features_info(steering_vec, threshold=0.01, top_k=5)\n",
    "display(df_top_5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
