{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46721f3d",
   "metadata": {},
   "source": [
    "# Classification Accuracy and Robustness Analysis\n",
    "\n",
    "This notebook analyzes the accuracy of our automated feature classification and assesses how classification errors might affect our main findings.\n",
    "\n",
    "## Research Question:\n",
    "**Does classification noise change our conclusion that formatting features have disproportionately higher impact on loss than alignment features?**\n",
    "\n",
    "## Approach:\n",
    "1. Load model classifications (DeepSeek) and human validation labels\n",
    "2. Compute confusion matrices to measure classification accuracy\n",
    "3. Perform sensitivity analysis: what level of misclassification would be needed to reverse our conclusions?\n",
    "4. Report bounds on the true effect size given observed classification accuracy\n",
    "\n",
    "## Data:\n",
    "- **Models**: Gemma 2 2B and Gemma 2 9B\n",
    "- **Categories**: Alignment and Formatting (Style)\n",
    "- **Validation**: 300 human-labeled samples per category per model\n",
    "- **Losses**: From experimental ablation studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d300bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Helper function to load JSON records\n",
    "def load_json_records(p: Path) -> list[dict]:\n",
    "    \"\"\"Load JSON data, handling both list and dict formats.\"\"\"\n",
    "    with p.open('r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    if isinstance(data, dict):\n",
    "        for k in (\"items\", \"records\", \"data\"):\n",
    "            if k in data and isinstance(data[k], list):\n",
    "                return data[k]\n",
    "        return [dict(feature_id=k, **(v if isinstance(v, dict) else {\"value\": v})) for k, v in data.items()]\n",
    "    assert isinstance(data, list), \"Expected list[dict] JSON structure\"\n",
    "    return data\n",
    "\n",
    "def extract_index_from_row(row: dict) -> int | None:\n",
    "    \"\"\"Extract feature index from various possible fields.\"\"\"\n",
    "    if 'index' in row and row['index'] is not None:\n",
    "        try:\n",
    "            return int(row['index'])\n",
    "        except Exception:\n",
    "            pass\n",
    "    fid = row.get('feature_id')\n",
    "    if isinstance(fid, str):\n",
    "        m = re.search(r'-(\\d+)$', fid)\n",
    "        if m:\n",
    "            try:\n",
    "                return int(m.group(1))\n",
    "            except Exception:\n",
    "                pass\n",
    "    return None\n",
    "\n",
    "def compute_confusion_matrix(model_labels: list, human_labels: list) -> dict:\n",
    "    \"\"\"\n",
    "    Compute confusion matrix given model and human labels.\n",
    "    Returns dict with TP, TN, FP, FN.\n",
    "    Assumes 'related' = positive class, 'not-related' = negative class\n",
    "    \"\"\"\n",
    "    assert len(model_labels) == len(human_labels), \"Label lists must be same length\"\n",
    "    \n",
    "    tp = sum(1 for m, h in zip(model_labels, human_labels) if m == 'related' and h == 'related')\n",
    "    tn = sum(1 for m, h in zip(model_labels, human_labels) if m == 'not-related' and h == 'not-related')\n",
    "    fp = sum(1 for m, h in zip(model_labels, human_labels) if m == 'related' and h == 'not-related')\n",
    "    fn = sum(1 for m, h in zip(model_labels, human_labels) if m == 'not-related' and h == 'related')\n",
    "    \n",
    "    return {'TP': tp, 'TN': tn, 'FP': fp, 'FN': fn}\n",
    "\n",
    "print(\"Helper functions loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbcbec8",
   "metadata": {},
   "source": [
    "## Configuration: Model and Loss Data\n",
    "\n",
    "Configure which model to analyze and provide the experimental loss data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5db51767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gemma-2-9b\n",
      "Baseline loss: 2.46\n",
      "Loss increase from ablating Alignment: 0.2400\n",
      "Loss increase from ablating Formatting (Style): 0.7500\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION: Select model and provide loss data\n",
    "# ============================================================\n",
    "\n",
    "# Choose model: 'gemma-2-2b' or 'gemma-2-9b'\n",
    "MODEL = 'gemma-2-9b'\n",
    "\n",
    "# Loss data (hardcoded from experimental results)\n",
    "# Format: {model: {'baseline_loss': X, 'alignment_loss': Y, 'formatting_loss': Z}}\n",
    "LOSS_DATA = {\n",
    "    'gemma-2-2b': {\n",
    "        'baseline_loss': 2.58,      # Baseline SimPO loss\n",
    "        'alignment_loss': 2.63,     # Loss after ablating alignment features\n",
    "        'formatting_loss': 5.12     # Loss after ablating formatting features\n",
    "    },\n",
    "    'gemma-2-9b': {\n",
    "        'baseline_loss': 2.46,      # Example values - UPDATE THESE\n",
    "        'alignment_loss': 2.70,     # Example values - UPDATE THESE\n",
    "        'formatting_loss': 3.21     # Example values - UPDATE THESE\n",
    "    }\n",
    "}\n",
    "\n",
    "# Get loss data for selected model\n",
    "baseline_loss = LOSS_DATA[MODEL]['baseline_loss']\n",
    "alignment_loss = LOSS_DATA[MODEL]['alignment_loss']\n",
    "formatting_loss = LOSS_DATA[MODEL]['formatting_loss']\n",
    "\n",
    "# Calculate loss increases\n",
    "loss_increase_A = alignment_loss - baseline_loss\n",
    "loss_increase_S = formatting_loss - baseline_loss\n",
    "\n",
    "print(f\"Model: {MODEL}\")\n",
    "print(f\"Baseline loss: {baseline_loss}\")\n",
    "print(f\"Loss increase from ablating Alignment: {loss_increase_A:.4f}\")\n",
    "print(f\"Loss increase from ablating Formatting (Style): {loss_increase_S:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2905144e",
   "metadata": {},
   "source": [
    "## Step 1: Load Model Classifications and Count Features\n",
    "\n",
    "Load the DeepSeek classifications for alignment and formatting, and count the number of features predicted in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3826d0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model classifications for gemma-2-9b...\n",
      "Alignment file: 12-gemmascope-res-16k_canonical_alignment_classified_deepseek-deepseek-chat-v3-0324.json\n",
      "Formatting file: 12-gemmascope-res-16k_canonical_formatting_classified_deepseek-deepseek-chat-v3-0324.json\n",
      "\n",
      "Feature counts from model predictions:\n",
      "  Predicted as Alignment-related: 2920\n",
      "  Predicted as Formatting-related (Style): 1889\n",
      "  Total features: 16381\n"
     ]
    }
   ],
   "source": [
    "# Define file paths based on model selection\n",
    "base_path = Path('../../outputs/feature_classification')\n",
    "\n",
    "# Map model names to their file patterns\n",
    "MODEL_FILES = {\n",
    "    'gemma-2-2b': {\n",
    "        'alignment': base_path / 'gemma-2-2b' / '12-gemmascope-res-65k_canonical_alignment_classified_deepseek-deepseek-chat-v3-0324.json',\n",
    "        'formatting': base_path / 'gemma-2-2b' / '12-gemmascope-res-65k_canonical_formatting_classified_deepseek-deepseek-chat-v3-0324.json',\n",
    "        'human_alignment': base_path / 'human_labels' / '12-gemmascope-res-65k__l0-21_human_labels_alignment.json',\n",
    "        'human_formatting': base_path / 'human_labels' / '12-gemmascope-res-65k__l0-21_human_labels_formatting.json'\n",
    "    },\n",
    "    'gemma-2-9b': {\n",
    "        'alignment': base_path / 'gemma-2-9b' / '12-gemmascope-res-16k_canonical_alignment_classified_deepseek-deepseek-chat-v3-0324.json',\n",
    "        'formatting': base_path / 'gemma-2-9b' / '12-gemmascope-res-16k_canonical_formatting_classified_deepseek-deepseek-chat-v3-0324.json',\n",
    "        'human_alignment': base_path / 'human_labels' / '12-gemmascope-res-16k_canonical_human_labels_alignment.json',\n",
    "        'human_formatting': base_path / 'human_labels' / '12-gemmascope-res-16k_canonical_human_labels_formatting.json'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Load model classifications\n",
    "alignment_file = MODEL_FILES[MODEL]['alignment']\n",
    "formatting_file = MODEL_FILES[MODEL]['formatting']\n",
    "\n",
    "print(f\"Loading model classifications for {MODEL}...\")\n",
    "print(f\"Alignment file: {alignment_file.name}\")\n",
    "print(f\"Formatting file: {formatting_file.name}\")\n",
    "\n",
    "# Load and process alignment classifications\n",
    "alignment_records = load_json_records(alignment_file)\n",
    "alignment_df = pd.DataFrame(alignment_records)\n",
    "alignment_df['feature_index'] = alignment_df.apply(lambda r: extract_index_from_row(r), axis=1)\n",
    "\n",
    "# Load and process formatting classifications\n",
    "formatting_records = load_json_records(formatting_file)\n",
    "formatting_df = pd.DataFrame(formatting_records)\n",
    "formatting_df['feature_index'] = formatting_df.apply(lambda r: extract_index_from_row(r), axis=1)\n",
    "\n",
    "# Count features predicted as positive in each category\n",
    "N_predicted_A = (alignment_df['label'] == 'related').sum()\n",
    "N_predicted_S = (formatting_df['label'] == 'related').sum()\n",
    "\n",
    "print(f\"\\nFeature counts from model predictions:\")\n",
    "print(f\"  Predicted as Alignment-related: {N_predicted_A}\")\n",
    "print(f\"  Predicted as Formatting-related (Style): {N_predicted_S}\")\n",
    "print(f\"  Total features: {len(alignment_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4562b3be",
   "metadata": {},
   "source": [
    "## Step 2: Load Human Labels and Compute Confusion Matrices\n",
    "\n",
    "Load human validation labels and compute confusion matrices to estimate classification accuracy and contamination rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f017021e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading human validation labels...\n",
      "Human alignment file: 12-gemmascope-res-16k_canonical_human_labels_alignment.json\n",
      "Human formatting file: 12-gemmascope-res-16k_canonical_human_labels_formatting.json\n",
      "\n",
      "Human labeled samples:\n",
      "  Alignment: 300 samples\n",
      "  Formatting: 300 samples\n",
      "  Sample alignment indices: [1622, 2118, 4191, 5846, 13620]\n",
      "  Sample formatting indices: [1622, 2118, 4191, 5846, 13620]\n",
      "\n",
      "Model data sample indices:\n",
      "  Alignment: [8, 49, 4, 54, 5, 25, 45, 22, 88, 41]\n",
      "  Formatting: [8, 49, 4, 54, 5, 25, 45, 22, 88, 41]\n",
      "\n",
      "Model predictions for human-labeled features:\n",
      "  Alignment: 300 samples\n",
      "  Formatting: 300 samples\n",
      "\n",
      "Validation sample sizes (after merge):\n",
      "  Alignment: 300 samples\n",
      "  Formatting: 300 samples\n",
      "\n",
      "Confusion Matrix for Alignment Classifier:\n",
      "  TP (Correct Positive): 27\n",
      "  TN (Correct Negative): 238\n",
      "  FP (False Positive): 24\n",
      "  FN (False Negative): 11\n",
      "  Accuracy: 88.33%\n",
      "\n",
      "Confusion Matrix for Formatting Classifier:\n",
      "  TP (Correct Positive): 23\n",
      "  TN (Correct Negative): 228\n",
      "  FP (False Positive): 5\n",
      "  FN (False Negative): 44\n",
      "  Accuracy: 83.67%\n"
     ]
    }
   ],
   "source": [
    "# Load human labels\n",
    "human_alignment_file = MODEL_FILES[MODEL]['human_alignment']\n",
    "human_formatting_file = MODEL_FILES[MODEL]['human_formatting']\n",
    "\n",
    "print(f\"Loading human validation labels...\")\n",
    "print(f\"Human alignment file: {human_alignment_file.name}\")\n",
    "print(f\"Human formatting file: {human_formatting_file.name}\")\n",
    "\n",
    "# Load human alignment labels\n",
    "human_alignment_records = load_json_records(human_alignment_file)\n",
    "human_alignment_df = pd.DataFrame(human_alignment_records)\n",
    "\n",
    "# Load human formatting labels\n",
    "human_formatting_records = load_json_records(human_formatting_file)\n",
    "human_formatting_df = pd.DataFrame(human_formatting_records)\n",
    "\n",
    "# Clean human data - use the 'feature_index' field directly if it exists\n",
    "if 'feature_index' in human_alignment_df.columns:\n",
    "    human_alignment_df_clean = human_alignment_df[['feature_index', 'label']].copy()\n",
    "    human_alignment_df_clean = human_alignment_df_clean.dropna(subset=['feature_index'])\n",
    "    human_alignment_df_clean['feature_index'] = human_alignment_df_clean['feature_index'].astype(int)\n",
    "else:\n",
    "    raise ValueError(\"Human alignment data missing 'feature_index' column\")\n",
    "\n",
    "if 'feature_index' in human_formatting_df.columns:\n",
    "    human_formatting_df_clean = human_formatting_df[['feature_index', 'label']].copy()\n",
    "    human_formatting_df_clean = human_formatting_df_clean.dropna(subset=['feature_index'])\n",
    "    human_formatting_df_clean['feature_index'] = human_formatting_df_clean['feature_index'].astype(int)\n",
    "else:\n",
    "    raise ValueError(\"Human formatting data missing 'feature_index' column\")\n",
    "\n",
    "print(f\"\\nHuman labeled samples:\")\n",
    "print(f\"  Alignment: {len(human_alignment_df_clean)} samples\")\n",
    "print(f\"  Formatting: {len(human_formatting_df_clean)} samples\")\n",
    "\n",
    "# Debug: Show sample of human indices\n",
    "if len(human_alignment_df_clean) > 0:\n",
    "    print(f\"  Sample alignment indices: {sorted(human_alignment_df_clean['feature_index'].head(5).tolist())}\")\n",
    "if len(human_formatting_df_clean) > 0:\n",
    "    print(f\"  Sample formatting indices: {sorted(human_formatting_df_clean['feature_index'].head(5).tolist())}\")\n",
    "\n",
    "# Get the feature indices that were human-labeled\n",
    "human_labeled_indices_A = set(human_alignment_df_clean['feature_index'].tolist())\n",
    "human_labeled_indices_S = set(human_formatting_df_clean['feature_index'].tolist())\n",
    "\n",
    "# Extract feature indices from model data and ensure they're integers\n",
    "alignment_df['feature_index'] = alignment_df.apply(lambda r: extract_index_from_row(r), axis=1)\n",
    "formatting_df['feature_index'] = formatting_df.apply(lambda r: extract_index_from_row(r), axis=1)\n",
    "\n",
    "# Debug: Show sample of model indices\n",
    "alignment_sample_indices = alignment_df['feature_index'].dropna().head(10).astype(int).tolist()\n",
    "formatting_sample_indices = formatting_df['feature_index'].dropna().head(10).astype(int).tolist()\n",
    "print(f\"\\nModel data sample indices:\")\n",
    "print(f\"  Alignment: {alignment_sample_indices}\")\n",
    "print(f\"  Formatting: {formatting_sample_indices}\")\n",
    "\n",
    "# Filter model predictions to only include human-labeled features\n",
    "# For alignment\n",
    "alignment_df_filtered = alignment_df[alignment_df['feature_index'].notna()].copy()\n",
    "alignment_df_filtered['feature_index'] = alignment_df_filtered['feature_index'].astype(int)\n",
    "alignment_df_filtered = alignment_df_filtered[alignment_df_filtered['feature_index'].isin(human_labeled_indices_A)]\n",
    "alignment_df_filtered = alignment_df_filtered[['feature_index', 'label']]\n",
    "\n",
    "# For formatting\n",
    "formatting_df_filtered = formatting_df[formatting_df['feature_index'].notna()].copy()\n",
    "formatting_df_filtered['feature_index'] = formatting_df_filtered['feature_index'].astype(int)\n",
    "formatting_df_filtered = formatting_df_filtered[formatting_df_filtered['feature_index'].isin(human_labeled_indices_S)]\n",
    "formatting_df_filtered = formatting_df_filtered[['feature_index', 'label']]\n",
    "\n",
    "print(f\"\\nModel predictions for human-labeled features:\")\n",
    "print(f\"  Alignment: {len(alignment_df_filtered)} samples\")\n",
    "print(f\"  Formatting: {len(formatting_df_filtered)} samples\")\n",
    "\n",
    "# Join model predictions with human labels for alignment\n",
    "merged_alignment = alignment_df_filtered.merge(\n",
    "    human_alignment_df_clean,\n",
    "    on='feature_index',\n",
    "    how='inner',\n",
    "    suffixes=('_model', '_human')\n",
    ")\n",
    "\n",
    "# Join model predictions with human labels for formatting\n",
    "merged_formatting = formatting_df_filtered.merge(\n",
    "    human_formatting_df_clean,\n",
    "    on='feature_index',\n",
    "    how='inner',\n",
    "    suffixes=('_model', '_human')\n",
    ")\n",
    "\n",
    "print(f\"\\nValidation sample sizes (after merge):\")\n",
    "print(f\"  Alignment: {len(merged_alignment)} samples\")\n",
    "print(f\"  Formatting: {len(merged_formatting)} samples\")\n",
    "\n",
    "# Compute confusion matrices\n",
    "cm_A = compute_confusion_matrix(\n",
    "    merged_alignment['label_model'].tolist(),\n",
    "    merged_alignment['label_human'].tolist()\n",
    ")\n",
    "\n",
    "cm_S = compute_confusion_matrix(\n",
    "    merged_formatting['label_model'].tolist(),\n",
    "    merged_formatting['label_human'].tolist()\n",
    ")\n",
    "\n",
    "# Extract values\n",
    "TP_A, TN_A, FP_A, FN_A = cm_A['TP'], cm_A['TN'], cm_A['FP'], cm_A['FN']\n",
    "TP_S, TN_S, FP_S, FN_S = cm_S['TP'], cm_S['TN'], cm_S['FP'], cm_S['FN']\n",
    "\n",
    "print(f\"\\nConfusion Matrix for Alignment Classifier:\")\n",
    "print(f\"  TP (Correct Positive): {TP_A}\")\n",
    "print(f\"  TN (Correct Negative): {TN_A}\")\n",
    "print(f\"  FP (False Positive): {FP_A}\")\n",
    "print(f\"  FN (False Negative): {FN_A}\")\n",
    "total_A = TP_A + TN_A + FP_A + FN_A\n",
    "if total_A > 0:\n",
    "    print(f\"  Accuracy: {(TP_A + TN_A) / total_A:.2%}\")\n",
    "else:\n",
    "    print(f\"  Accuracy: N/A (no samples)\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix for Formatting Classifier:\")\n",
    "print(f\"  TP (Correct Positive): {TP_S}\")\n",
    "print(f\"  TN (Correct Negative): {TN_S}\")\n",
    "print(f\"  FP (False Positive): {FP_S}\")\n",
    "print(f\"  FN (False Negative): {FN_S}\")\n",
    "total_S = TP_S + TN_S + FP_S + FN_S\n",
    "if total_S > 0:\n",
    "    print(f\"  Accuracy: {(TP_S + TN_S) / total_S:.2%}\")\n",
    "else:\n",
    "    print(f\"  Accuracy: N/A (no samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff400a5",
   "metadata": {},
   "source": [
    "## Step 3: Calculate Observed Loss Per Feature (LPF)\n",
    "\n",
    "Calculate the observed loss per feature based on our classifier predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd552be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed LPF for Alignment: 8.22e-05\n",
      "Observed LPF for Formatting: 3.97e-04\n",
      "Observed Ratio (Formatting/Alignment): 4.83x\n",
      "\n",
      "Our main claim: Formatting features have ~4.8x higher impact than alignment features.\n"
     ]
    }
   ],
   "source": [
    "# Calculate observed LPF from our classifier predictions\n",
    "lpf_A_observed = loss_increase_A / N_predicted_A\n",
    "lpf_S_observed = loss_increase_S / N_predicted_S\n",
    "ratio_observed = lpf_S_observed / lpf_A_observed\n",
    "\n",
    "print(f\"Observed LPF for Alignment: {lpf_A_observed:.2e}\")\n",
    "print(f\"Observed LPF for Formatting: {lpf_S_observed:.2e}\")\n",
    "print(f\"Observed Ratio (Formatting/Alignment): {ratio_observed:.2f}x\")\n",
    "print(f\"\\nOur main claim: Formatting features have ~{ratio_observed:.1f}x higher impact than alignment features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1066bb",
   "metadata": {},
   "source": [
    "## Step 4: Classification Accuracy Summary\n",
    "\n",
    "Report the classifier accuracy from human validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5933a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CLASSIFICATION ACCURACY (from human validation)\n",
      "============================================================\n",
      "\n",
      "Alignment Classifier:\n",
      "  Accuracy: 88.3%\n",
      "  Precision: 52.9% (of features we called 'alignment', 52.9% actually are)\n",
      "  Recall: 71.1% (of true alignment features, we identified 71.1%)\n",
      "\n",
      "Formatting Classifier:\n",
      "  Accuracy: 83.7%\n",
      "  Precision: 82.1% (of features we called 'formatting', 82.1% actually are)\n",
      "  Recall: 34.3% (of true formatting features, we identified 34.3%)\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification metrics\n",
    "accuracy_A = (TP_A + TN_A) / (TP_A + TN_A + FP_A + FN_A) if (TP_A + TN_A + FP_A + FN_A) > 0 else 0\n",
    "accuracy_S = (TP_S + TN_S) / (TP_S + TN_S + FP_S + FN_S) if (TP_S + TN_S + FP_S + FN_S) > 0 else 0\n",
    "\n",
    "# Precision (of positive predictions)\n",
    "precision_A = TP_A / (TP_A + FP_A) if (TP_A + FP_A) > 0 else 0\n",
    "precision_S = TP_S / (TP_S + FP_S) if (TP_S + FP_S) > 0 else 0\n",
    "\n",
    "# Recall (of actual positives)\n",
    "recall_A = TP_A / (TP_A + FN_A) if (TP_A + FN_A) > 0 else 0\n",
    "recall_S = TP_S / (TP_S + FN_S) if (TP_S + FN_S) > 0 else 0\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CLASSIFICATION ACCURACY (from human validation)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nAlignment Classifier:\")\n",
    "print(f\"  Accuracy: {accuracy_A:.1%}\")\n",
    "print(f\"  Precision: {precision_A:.1%} (of features we called 'alignment', {precision_A:.1%} actually are)\")\n",
    "print(f\"  Recall: {recall_A:.1%} (of true alignment features, we identified {recall_A:.1%})\")\n",
    "\n",
    "print(f\"\\nFormatting Classifier:\")\n",
    "print(f\"  Accuracy: {accuracy_S:.1%}\")\n",
    "print(f\"  Precision: {precision_S:.1%} (of features we called 'formatting', {precision_S:.1%} actually are)\")\n",
    "print(f\"  Recall: {recall_S:.1%} (of true formatting features, we identified {recall_S:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607ea6ce",
   "metadata": {},
   "source": [
    "## Step 5: Sensitivity Analysis\n",
    "\n",
    "**Core Question:** Given the observed classification accuracy, how confident can we be in our finding?\n",
    "\n",
    "**Important Context:** This is a **three-category problem**:\n",
    "- Alignment-related features\n",
    "- Formatting-related features  \n",
    "- Unrelated features (the vast majority of the SAE features)\n",
    "\n",
    "With 55% precision on alignment, the misclassified features in the alignment bucket could be:\n",
    "- High-impact formatting features (making our claim conservative), OR\n",
    "- Zero-impact unrelated features (making alignment LPF appear lower than reality)\n",
    "\n",
    "We'll examine both scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19aca3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SENSITIVITY ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Classification quality summary:\n",
      "  Alignment: 52.9% precision → ~1374 of 2920 features likely misclassified\n",
      "  Formatting: 82.1% precision → ~337 of 1889 features likely misclassified\n",
      "\n",
      "IMPORTANT: This is a 3-category problem (alignment/formatting/unrelated).\n",
      "Total SAE features: 16,381, but most are unrelated to either category.\n",
      "\n",
      "======================================================================\n",
      "SCENARIO 1: Misclassifications are UNRELATED features (zero impact)\n",
      "======================================================================\n",
      "Assumption: False positives are unrelated features with no impact on loss.\n",
      "This represents the worst case for our claim.\n",
      "\n",
      "Result:\n",
      "  Alignment LPF: 1.55e-04 (vs observed 8.22e-05)\n",
      "  Formatting LPF: 4.83e-04 (vs observed 3.97e-04)\n",
      "  Ratio: 3.11x\n",
      "\n",
      "Interpretation: Even if ALL misclassified features are unrelated noise,\n",
      "formatting is still 3.1x more impactful than alignment.\n",
      "Our finding is ROBUST.\n",
      "\n",
      "======================================================================\n",
      "SCENARIO 2: Misclassifications are from the OTHER category\n",
      "======================================================================\n",
      "Assumption: False positives in alignment are formatting features (and vice versa).\n",
      "This represents the best case for our claim.\n",
      "\n",
      "Result:\n",
      "  Alignment LPF: 1.79e-05 (vs observed 8.22e-05)\n",
      "  Formatting LPF: 8.17e-04 (vs observed 3.97e-04)\n",
      "  Ratio: 45.56x\n",
      "\n",
      "Interpretation: If misclassified features are contamination from the\n",
      "opposite category, the true ratio is 45.6x - even LARGER than observed.\n",
      "This makes our claim MORE CONSERVATIVE.\n",
      "\n",
      "======================================================================\n",
      "SCENARIO 3: Reality is probably between these bounds\n",
      "======================================================================\n",
      "\n",
      "  Worst case (all FPs are unrelated): 3.11x\n",
      "  Observed (unadjusted):              4.83x\n",
      "  Best case (all FPs are opposite):   45.56x\n",
      "\n",
      "✓ Even in the worst case, formatting is 3.1x more impactful.\n",
      "  Our finding is ROBUST to classification errors.\n",
      "\n",
      "======================================================================\n",
      "CONCLUSION\n",
      "======================================================================\n",
      "\n",
      "Our finding is ROBUST. Even assuming all 1374 misclassified\n",
      "alignment features are unrelated noise (worst case), formatting features\n",
      "remain 3.1x more impactful than alignment features.\n",
      "\n",
      "Note: Most misclassified features are likely UNRELATED (not opposite category),\n",
      "since alignment and formatting are both small subsets of the total feature space.\n"
     ]
    }
   ],
   "source": [
    "# Estimate the number of misclassified features using precision\n",
    "estimated_FP_A = N_predicted_A * (1 - precision_A) if precision_A > 0 else 0\n",
    "estimated_FP_S = N_predicted_S * (1 - precision_S) if precision_S > 0 else 0\n",
    "\n",
    "estimated_correct_A = N_predicted_A - estimated_FP_A\n",
    "estimated_correct_S = N_predicted_S - estimated_FP_S\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SENSITIVITY ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nClassification quality summary:\")\n",
    "print(f\"  Alignment: {precision_A:.1%} precision → ~{estimated_FP_A:.0f} of {N_predicted_A} features likely misclassified\")\n",
    "print(f\"  Formatting: {precision_S:.1%} precision → ~{estimated_FP_S:.0f} of {N_predicted_S} features likely misclassified\")\n",
    "print()\n",
    "print(f\"IMPORTANT: This is a 3-category problem (alignment/formatting/unrelated).\")\n",
    "print(f\"Total SAE features: {len(alignment_df):,}, but most are unrelated to either category.\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SCENARIO 1: Misclassifications are UNRELATED features (zero impact)\")\n",
    "print(\"=\"*70)\n",
    "print(\"Assumption: False positives are unrelated features with no impact on loss.\")\n",
    "print(\"This represents the worst case for our claim.\")\n",
    "print()\n",
    "\n",
    "if estimated_correct_A > 0 and estimated_correct_S > 0:\n",
    "    # If FPs have zero impact, only correct classifications contributed to loss\n",
    "    lpf_A_worst = loss_increase_A / estimated_correct_A\n",
    "    lpf_S_worst = loss_increase_S / estimated_correct_S\n",
    "    ratio_worst = lpf_S_worst / lpf_A_worst\n",
    "    \n",
    "    print(f\"Result:\")\n",
    "    print(f\"  Alignment LPF: {lpf_A_worst:.2e} (vs observed {lpf_A_observed:.2e})\")\n",
    "    print(f\"  Formatting LPF: {lpf_S_worst:.2e} (vs observed {lpf_S_observed:.2e})\")\n",
    "    print(f\"  Ratio: {ratio_worst:.2f}x\")\n",
    "    print()\n",
    "    if ratio_worst > 1:\n",
    "        print(f\"Interpretation: Even if ALL misclassified features are unrelated noise,\")\n",
    "        print(f\"formatting is still {ratio_worst:.1f}x more impactful than alignment.\")\n",
    "        print(f\"Our finding is ROBUST.\")\n",
    "    else:\n",
    "        print(f\"Interpretation: If misclassified features are all unrelated, the\")\n",
    "        print(f\"ratio drops below 1.0, which would challenge our claim.\")\n",
    "        print(f\"Our finding is SENSITIVE to classification quality.\")\n",
    "else:\n",
    "    print(\"Cannot compute - too few correct classifications\")\n",
    "    ratio_worst = None\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SCENARIO 2: Misclassifications are from the OTHER category\")\n",
    "print(\"=\"*70)\n",
    "print(\"Assumption: False positives in alignment are formatting features (and vice versa).\")\n",
    "print(\"This represents the best case for our claim.\")\n",
    "print()\n",
    "\n",
    "if estimated_correct_A > 0 and estimated_correct_S > 0:\n",
    "    # Worst contamination: FPs in alignment have formatting impact\n",
    "    # Remove their contribution from alignment\n",
    "    loss_from_FP_A = estimated_FP_A * lpf_S_observed\n",
    "    pure_loss_A = max(0, loss_increase_A - loss_from_FP_A)\n",
    "    \n",
    "    # FPs in formatting have alignment impact\n",
    "    loss_from_FP_S = estimated_FP_S * lpf_A_observed  \n",
    "    pure_loss_S = max(0, loss_increase_S - loss_from_FP_S)\n",
    "    \n",
    "    # Redistribute to correct categories\n",
    "    adjusted_loss_A = pure_loss_A + loss_from_FP_S\n",
    "    adjusted_loss_S = pure_loss_S + loss_from_FP_A\n",
    "    \n",
    "    lpf_A_best = adjusted_loss_A / estimated_correct_A\n",
    "    lpf_S_best = adjusted_loss_S / estimated_correct_S\n",
    "    ratio_best = lpf_S_best / lpf_A_best if lpf_A_best > 0 else float('inf')\n",
    "    \n",
    "    print(f\"Result:\")\n",
    "    print(f\"  Alignment LPF: {lpf_A_best:.2e} (vs observed {lpf_A_observed:.2e})\")\n",
    "    print(f\"  Formatting LPF: {lpf_S_best:.2e} (vs observed {lpf_S_observed:.2e})\")\n",
    "    print(f\"  Ratio: {ratio_best:.2f}x\")\n",
    "    print()\n",
    "    print(f\"Interpretation: If misclassified features are contamination from the\")\n",
    "    print(f\"opposite category, the true ratio is {ratio_best:.1f}x - even LARGER than observed.\")\n",
    "    print(f\"This makes our claim MORE CONSERVATIVE.\")\n",
    "else:\n",
    "    print(\"Cannot compute\")\n",
    "    ratio_best = None\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SCENARIO 3: Reality is probably between these bounds\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(f\"  Worst case (all FPs are unrelated): {ratio_worst:.2f}x\" if ratio_worst else \"  Worst case: N/A\")\n",
    "print(f\"  Observed (unadjusted):              {ratio_observed:.2f}x\")\n",
    "print(f\"  Best case (all FPs are opposite):   {ratio_best:.2f}x\" if ratio_best else \"  Best case: N/A\")\n",
    "print()\n",
    "\n",
    "if ratio_worst and ratio_best:\n",
    "    if ratio_worst > 1:\n",
    "        print(f\"✓ Even in the worst case, formatting is {ratio_worst:.1f}x more impactful.\")\n",
    "        print(f\"  Our finding is ROBUST to classification errors.\")\n",
    "    elif ratio_worst < 1 < ratio_best:\n",
    "        print(f\"⚠ Worst case ratio is {ratio_worst:.2f}x (below 1.0), but best case is {ratio_best:.2f}x.\")\n",
    "        print(f\"  The true value likely lies between these bounds.\")\n",
    "        print(f\"  Our finding is MODERATELY ROBUST, but sensitive to the composition\")\n",
    "        print(f\"  of false positives (unrelated vs. opposite category).\")\n",
    "    else:\n",
    "        print(f\"⚠ Worst case ratio is {ratio_worst:.2f}x, suggesting sensitivity to errors.\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"CONCLUSION\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "if ratio_worst and ratio_worst > 1:\n",
    "    print(f\"Our finding is ROBUST. Even assuming all {estimated_FP_A:.0f} misclassified\")\n",
    "    print(f\"alignment features are unrelated noise (worst case), formatting features\")\n",
    "    print(f\"remain {ratio_worst:.1f}x more impactful than alignment features.\")\n",
    "elif ratio_worst and ratio_worst < 1:\n",
    "    print(f\"Our finding shows MODERATE sensitivity to classification quality.\")\n",
    "    print(f\"The observed {ratio_observed:.1f}x ratio could shrink to {ratio_worst:.2f}x if most\")\n",
    "    print(f\"misclassified features are unrelated, or grow to {ratio_best:.2f}x if they're\" if ratio_best else \"misclassified features are unrelated.\")\n",
    "    print(f\"cross-category contamination.\")\n",
    "    print()\n",
    "    print(f\"Recommendation: Report the range [{ratio_worst:.1f}x to {ratio_best:.1f}x] and\" if ratio_best else f\"Recommendation: Report {ratio_worst:.1f}x as lower bound and\")\n",
    "    print(f\"acknowledge the {precision_A:.0%} alignment precision as a limitation.\")\n",
    "else:\n",
    "    print(\"Unable to determine robustness due to insufficient data.\")\n",
    "\n",
    "print()\n",
    "print(\"Note: Most misclassified features are likely UNRELATED (not opposite category),\")\n",
    "print(\"since alignment and formatting are both small subsets of the total feature space.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c2b184",
   "metadata": {},
   "source": [
    "## Step 6: Summary and Conclusion for Rebuttal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f16a1470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SUMMARY FOR REBUTTAL\n",
      "======================================================================\n",
      "\n",
      "            Category Observed LPF Accuracy Precision\n",
      "           Alignment     8.22e-05    88.3%     52.9%\n",
      "          Formatting     3.97e-04    83.7%     82.1%\n",
      "Ratio (Format/Align)        4.83x        -         -\n",
      "\n",
      "Sensitivity bounds: [3.11x, 45.56x]\n",
      "\n",
      "======================================================================\n",
      "KEY POINTS FOR REBUTTAL\n",
      "======================================================================\n",
      "\n",
      "1. VALIDATION:\n",
      "   Validated automated classification on 300 randomly sampled features \n",
      "   per category, achieving 88% accuracy (alignment) and \n",
      "   84% accuracy (formatting).\n",
      "\n",
      "2. THREE-CATEGORY PROBLEM:\n",
      "   SAE has 16,381 features total, but most are unrelated to either\n",
      "   alignment or formatting. Misclassifications could be:\n",
      "   - Unrelated features (diluting the observed effect)\n",
      "   - Cross-category contamination (inflating the observed effect)\n",
      "\n",
      "3. PRECISION ANALYSIS:\n",
      "   - Alignment: 53% precision → ~1374 of 2920 likely misclassified\n",
      "   - Formatting: 82% precision → ~337 of 1889 likely misclassified\n",
      "\n",
      "4. SENSITIVITY BOUNDS:\n",
      "   Worst case (FPs are unrelated): 3.11x → Finding is ROBUST\n",
      "   Even assuming all misclassifications are noise, formatting remains\n",
      "   3.1x more impactful than alignment.\n",
      "\n",
      "5. RECOMMENDATION:\n",
      "   Report: Our finding is robust to classification errors. Even in the\n",
      "   worst case (all misclassifications are unrelated features), formatting\n",
      "   features remain 3.1x more impactful.\n",
      "\n",
      "\n",
      "======================================================================\n",
      "SUGGESTED TEXT FOR PAPER\n",
      "======================================================================\n",
      "\n",
      "\"We validated our automated classification on 300 randomly sampled features\n",
      "per category (from a total of 16,381 SAE features), achieving 88% \n",
      "and 84% accuracy respectively. Sensitivity analysis accounting for \n",
      "the three-category nature of the problem (alignment/formatting/unrelated) shows \n",
      "our finding is robust: even if all misclassified features are unrelated noise, \n",
      "formatting features remain 3.1x more impactful than alignment features.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"SUMMARY FOR REBUTTAL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'Category': ['Alignment', 'Formatting', 'Ratio (Format/Align)'],\n",
    "    'Observed LPF': [\n",
    "        f'{lpf_A_observed:.2e}',\n",
    "        f'{lpf_S_observed:.2e}',\n",
    "        f'{ratio_observed:.2f}x'\n",
    "    ],\n",
    "    'Accuracy': [\n",
    "        f'{accuracy_A:.1%}',\n",
    "        f'{accuracy_S:.1%}',\n",
    "        '-'\n",
    "    ],\n",
    "    'Precision': [\n",
    "        f'{precision_A:.1%}',\n",
    "        f'{precision_S:.1%}',\n",
    "        '-'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + summary_df.to_string(index=False))\n",
    "\n",
    "if 'ratio_worst' in locals() and 'ratio_best' in locals() and ratio_worst and ratio_best:\n",
    "    print(f\"\\nSensitivity bounds: [{ratio_worst:.2f}x, {ratio_best:.2f}x]\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KEY POINTS FOR REBUTTAL\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\"\"\n",
    "1. VALIDATION:\n",
    "   Validated automated classification on 300 randomly sampled features \n",
    "   per category, achieving {accuracy_A:.0%} accuracy (alignment) and \n",
    "   {accuracy_S:.0%} accuracy (formatting).\n",
    "\n",
    "2. THREE-CATEGORY PROBLEM:\n",
    "   SAE has {len(alignment_df):,} features total, but most are unrelated to either\n",
    "   alignment or formatting. Misclassifications could be:\n",
    "   - Unrelated features (diluting the observed effect)\n",
    "   - Cross-category contamination (inflating the observed effect)\n",
    "\n",
    "3. PRECISION ANALYSIS:\n",
    "   - Alignment: {precision_A:.0%} precision → ~{estimated_FP_A:.0f} of {N_predicted_A} likely misclassified\n",
    "   - Formatting: {precision_S:.0%} precision → ~{estimated_FP_S:.0f} of {N_predicted_S} likely misclassified\n",
    "\n",
    "4. SENSITIVITY BOUNDS:\"\"\")\n",
    "\n",
    "if 'ratio_worst' in locals() and ratio_worst:\n",
    "    if ratio_worst > 1:\n",
    "        print(f\"   Worst case (FPs are unrelated): {ratio_worst:.2f}x → Finding is ROBUST\")\n",
    "        print(f\"   Even assuming all misclassifications are noise, formatting remains\")\n",
    "        print(f\"   {ratio_worst:.1f}x more impactful than alignment.\")\n",
    "    else:\n",
    "        print(f\"   Worst case (FPs are unrelated): {ratio_worst:.2f}x\")\n",
    "        print(f\"   Best case (FPs are opposite category): {ratio_best:.2f}x\" if 'ratio_best' in locals() and ratio_best else \"\")\n",
    "        print(f\"   True value likely between these bounds. Finding shows moderate\")\n",
    "        print(f\"   sensitivity to classification quality.\")\n",
    "\n",
    "print(f\"\"\"\n",
    "5. RECOMMENDATION:\"\"\")\n",
    "\n",
    "if 'ratio_worst' in locals() and ratio_worst and ratio_worst > 1:\n",
    "    print(f\"   Report: Our finding is robust to classification errors. Even in the\")\n",
    "    print(f\"   worst case (all misclassifications are unrelated features), formatting\")\n",
    "    print(f\"   features remain {ratio_worst:.1f}x more impactful.\")\n",
    "else:\n",
    "    print(f\"   Report: Observed ratio of {ratio_observed:.1f}x with sensitivity bounds\")\n",
    "    print(f\"   of [{ratio_worst:.2f}x, {ratio_best:.2f}x]. Acknowledge {precision_A:.0%} alignment\" if 'ratio_worst' in locals() and 'ratio_best' in locals() and ratio_worst and ratio_best else f\"   Report: Observed ratio of {ratio_observed:.1f}x. Acknowledge {precision_A:.0%} alignment\")\n",
    "    print(f\"   precision as a limitation that introduces uncertainty.\")\n",
    "\n",
    "print(f\"\"\"\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SUGGESTED TEXT FOR PAPER\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if 'ratio_worst' in locals() and ratio_worst and ratio_worst > 1:\n",
    "    print(f'''\n",
    "\"We validated our automated classification on 300 randomly sampled features\n",
    "per category (from a total of {len(alignment_df):,} SAE features), achieving {accuracy_A:.0%} \n",
    "and {accuracy_S:.0%} accuracy respectively. Sensitivity analysis accounting for \n",
    "the three-category nature of the problem (alignment/formatting/unrelated) shows \n",
    "our finding is robust: even if all misclassified features are unrelated noise, \n",
    "formatting features remain {ratio_worst:.1f}x more impactful than alignment features.\"\n",
    "''')\n",
    "else:\n",
    "    print(f'''\n",
    "\"We validated our automated classification on 300 randomly sampled features\n",
    "per category (from a total of {len(alignment_df):,} SAE features), achieving {accuracy_A:.0%} \n",
    "and {accuracy_S:.0%} accuracy respectively. Given the three-category nature of \n",
    "the problem (alignment/formatting/unrelated) and the {precision_A:.0%} precision on \n",
    "alignment, sensitivity analysis yields bounds of [{ratio_worst:.2f}x, {ratio_best:.2f}x] \n",
    "on the true formatting/alignment ratio. We report the observed {ratio_observed:.1f}x with \n",
    "this uncertainty acknowledged.\"\n",
    "''' if 'ratio_worst' in locals() and 'ratio_best' in locals() and ratio_worst and ratio_best else f'''\n",
    "\"We validated our automated classification on 300 randomly sampled features\n",
    "per category, achieving {accuracy_A:.0%} and {accuracy_S:.0%} accuracy respectively.\n",
    "We acknowledge the {precision_A:.0%} precision on alignment classification as a \n",
    "limitation that introduces uncertainty in the magnitude of the observed {ratio_observed:.1f}x ratio.\"\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
