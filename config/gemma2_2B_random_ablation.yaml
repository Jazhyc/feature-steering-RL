# Training configuration with random feature ablation baseline (2B model)
# Uses same hyperparameters as gemma2_2B.yaml but masks random features during training
defaults:
  - architecture: gemma2_2B
  - training: gemma2_2B
  - wandb: gemma2_2B_train_ablation
  - _self_

# Model saving configuration
models_dir: "models/Gemma2-2B-train-ablation"

# Random ablation configuration
# Set ablation_random_count to the number of features to randomly ablate
# To match style ablation experiment: use 15391 for 2B model
ablation_random_count: 15391

# Optional: set a seed for reproducibility
ablation_random_seed: 42

# Override any settings here if needed
hydra:
  run:
    dir: logs/hydra_runs/${now:%Y-%m-%d_%H-%M-%S}
